# ğŸš— Shift-by-Wire Fault Detection using Explainable AI (SHAP & LIME)

> **Explainable AIâ€“based fault detection for Shift-by-Wire automotive systems using Isolation Forest, SHAP, and LIME.**

---

## ğŸ“˜ Overview
This project demonstrates **data-driven fault detection** and **explainability** for a simulated **Shift-by-Wire (SBW)** system â€” an advanced automotive mechanism that replaces mechanical linkages with electronic controls.

The pipeline uses **unsupervised machine learning (Isolation Forest)** to detect anomalies in SBW sensor behavior and employs **SHAP** and **LIME** to interpret and visualize *why* faults are detected â€” bridging the gap between **AI predictions** and **engineering understanding**.

---

## ğŸ§­ Objectives
- Simulate realistic **Shift-by-Wire sensor data** (torque, actuator, clutch pressure, gear).  
- Engineer **dynamic features** that capture system health and transitions.  
- Detect **faults** using **Isolation Forest** (unsupervised anomaly detection).  
- Explain **model reasoning** using **SHAP** (global & local) and **LIME** (local).  
- Visualize fault behavior with **interpretable plots** for engineers.

---

## âš™ï¸ System Architecture

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Synthetic SBW Sensor Dataset â”‚
â”‚ torque_demand, torque_actual, â”‚
â”‚ actuator_pos, clutch_pressure â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚
Feature Engineering (KPIs)
â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Isolation Forest Model â”‚ â† Fault Detection
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚
Explainability (SHAP & LIME)
â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Visualization & Insights â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜


---

## ğŸ§® Dataset Description

| Feature | Description | Unit |
|----------|--------------|------|
| `time_s` | Timestamp | s |
| `gear` | Gear position (1â€“6) | â€“ |
| `torque_demand` | Driver-requested torque | Nm |
| `torque_actual` | Delivered torque (with injected faults) | Nm |
| `actuator_pos` | Actuator position | % |
| `clutch_pressure` | Hydraulic clutch pressure | bar |

During generation, random torque dropouts are introduced to simulate actuator lags and signal inconsistencies.

---

## ğŸ§  Feature Engineering

| Feature | Formula | Purpose |
|----------|----------|----------|
| `torque_error_rm` | Rolling mean of (demand âˆ’ actual) | Detect actuator or control lag |
| `torque_rate_rm` | Rolling mean of Î”torque/Î”time | Capture response speed |
| `pressure_rate` | Î”pressure/Î”time | Identify hydraulic instability |
| `actuator_pos` | Raw actuator position | Monitor displacement behavior |

These features represent the **core KPIs** that define SBW health.

---

## ğŸ¤– Fault Detection Model

| Component | Description |
|------------|-------------|
| **Algorithm** | Isolation Forest |
| **Type** | Unsupervised anomaly detection |
| **Contamination** | 0.05 (â‰ˆ5% expected faults) |
| **Goal** | Learn normal sensor behavior and flag deviations as faults |

```python
from sklearn.ensemble import IsolationForest
model = IsolationForest(contamination=0.05, random_state=42)
df['fault_flag'] = model.fit_predict(X_scaled)

ğŸ“Š Visualization

| Visualization    | Insight                                                      |
| ---------------- | ------------------------------------------------------------ |
| Torque-Time Plot | Fault points (red) show torque dropouts                      |
| SHAP Summary     | `pressure_rate` & `torque_error_rm` dominate fault detection |
| SHAP Waterfall   | Breaks down one predictionâ€™s sensor-level reasoning          |
| LIME Table       | Human-readable explanation of a local fault event            |

ğŸ“ˆ Key Results
| Metric                    | Value / Insight                           |
| ------------------------- | ----------------------------------------- |
| Dataset Size              | 3000 samples                              |
| Features                  | 4 engineered KPIs                         |
| Detected Faults           | â‰ˆ5%                                       |
| Most Influential Features | `pressure_rate`, `torque_error_rm`        |
| Explainability Outcome    | Transparent, sensor-level fault reasoning |

ğŸ§° Tech Stack

| Category       | Tools               |
| -------------- | ------------------- |
| Language       | Python 3            |
| ML Framework   | Scikit-learn        |
| Explainability | SHAP, LIME          |
| Visualization  | Matplotlib, Seaborn |
| Data Handling  | Pandas, NumPy       |
| Environment    | Jupyter Notebook    |

The model detected anomalies primarily when actuator position and torque rate deviated from normal operation.
SHAP confirmed these featuresâ€™ dominant impact, while LIME provided localized explanations showing clutch pressure spikes and torque errors as the root cause of specific faults.
